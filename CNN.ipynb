{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %pip install numpy\n",
        "# %pip install opencv_python_headless\n",
        "# %pip install torch\n",
        "# %pip install matplotlib\n",
        "# %pip install pandas\n",
        "# %pip install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YtHmq905RxUh"
      },
      "outputs": [],
      "source": [
        "# Importing Necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import ast\n",
        "import torch\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zYvZ0Zc6ShyN"
      },
      "outputs": [],
      "source": [
        "# Define a function to create the image dataset and labels\n",
        "def create_dataset():\n",
        "    img_data_array = [] \n",
        "    class_name = []      \n",
        "    \n",
        "    \n",
        "    data = torch.load(\"crop_data.pt\")\n",
        "    \n",
        "    for item in data:\n",
        "        label = item[\"label\"]\n",
        "        image_tensor = item[\"image\"]\n",
        "\n",
        "        img_data_array.append(image_tensor)\n",
        "        class_name.append(label)\n",
        "\n",
        "    return img_data_array, class_name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlSbrkoTSlKL",
        "outputId": "84b60126-94a4-4fb2-fd15-0a20cfbde414"
      },
      "outputs": [],
      "source": [
        "img_data , class_name = create_dataset()\n",
        "class_name = np.array(class_name)\n",
        "class_name = class_name.ravel()\n",
        "le = LabelEncoder()\n",
        "class_name = le.fit_transform(class_name)\n",
        "len(img_data)\n",
        "print(class_name)\n",
        "len(class_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPj6gd-6SfEe",
        "outputId": "9df0922e-77cd-426a-a290-1dc296312bdc"
      },
      "outputs": [],
      "source": [
        "print(f\"First image shape: {img_data[0].shape}\")\n",
        "print(f\"First label (age, weight): {class_name[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Implementing a CNN in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "A4B7vm32SnqP"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim\n",
        "import torch.utils.data as Data\n",
        "from torch import Tensor\n",
        "from torch.autograd import Variable\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nz8oeFySq4S",
        "outputId": "0dc04b34-3ec4-4b03-8157-acd231601bf5"
      },
      "outputs": [],
      "source": [
        "# version of pytorch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3fJp514UsxH"
      },
      "outputs": [],
      "source": [
        "images_tensor = img_data # Image data as tensor\n",
        "labels_tensor = torch.tensor(class_name)  # Labels as tensor\n",
        "\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    images_tensor, labels_tensor, test_size=0.3, random_state=42)\n",
        "\n",
        "torch_dataset_train = Data.TensorDataset(\n",
        "    torch.Tensor(np.array(train_images)),  # Image data converted to a PyTorch tensor\n",
        "    torch.Tensor(np.array(train_labels))  # Class labels converted to a PyTorch tensor\n",
        ")\n",
        "\n",
        "torch_dataset_test = Data.TensorDataset(\n",
        "    torch.Tensor(np.array(test_images)),  # Image data converted to a PyTorch tensor\n",
        "    torch.Tensor(np.array(test_labels))  # Class labels converted to a PyTorch tensor\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ZDRJ_-3YUuUm"
      },
      "outputs": [],
      "source": [
        "# Define the trainloader and testloader for batching and shuffling data\n",
        "trainloader = Data.DataLoader(\n",
        "    torch_dataset_train,  # Training dataset\n",
        "    batch_size=8,         # Batch size for training\n",
        "    shuffle=True          # Shuffle the training data\n",
        ")\n",
        "\n",
        "testloader = Data.DataLoader(\n",
        "    torch_dataset_test,   # Testing dataset\n",
        "    batch_size=8,         # Batch size for testing\n",
        "    shuffle=True          # Shuffle the testing data\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eVAMgi_Uv-l",
        "outputId": "a6380b3b-1b22-42f8-cf50-32aec4c692e6"
      },
      "outputs": [],
      "source": [
        "# Create an iterator for the training data loader\n",
        "dataiter = iter(trainloader)\n",
        "\n",
        "# Get the next batch of data\n",
        "images = next(dataiter)\n",
        "\n",
        "# Access the shape of the images in the batch\n",
        "images[0].shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the CNN model architecture\n",
        "class CNNNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNNet, self).__init__()\n",
        "\n",
        "        self.cnn_layers = nn.Sequential(\n",
        "            # Define a 2D convolution layer with 3 input channels, 16 output channels, and a 5x5 kernel\n",
        "            nn.Conv2d(3, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2)),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            # Define another convolution layer with 16 input channels, 3 output channels, and a 50x50 kernel\n",
        "            nn.Conv2d(16, 3, kernel_size=(50, 50), stride=(1, 1)),\n",
        "            nn.MaxPool2d(kernel_size=1, stride=1, padding=0, ceil_mode=False)\n",
        "        )\n",
        "\n",
        "        self.linear_layers = nn.Sequential(\n",
        "            # Define a fully connected layer with 3 input features and 3 output features\n",
        "            nn.Linear(3, 21)\n",
        "        )\n",
        "\n",
        "    # Define the forward pass\n",
        "    def forward(self, x):\n",
        "        x = self.cnn_layers(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.linear_layers(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xishQtqOSvMN",
        "outputId": "97b94cfb-927e-4675-fb39-daaee4732770"
      },
      "outputs": [],
      "source": [
        "# Define the CNN model architecture\n",
        "class CNNNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNNet, self).__init__()\n",
        "\n",
        "        self.cnn_layers = nn.Sequential(\n",
        "            # Define a 2D convolution layer with 3 input channels, 16 output channels, and a 5x5 kernel\n",
        "            nn.Conv2d(3, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2)),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            # Define another convolution layer with 16 input channels, 3 output channels, and a 50x50 kernel\n",
        "            nn.Conv2d(16, 3, kernel_size=(50, 50), stride=(1, 1)),\n",
        "            nn.MaxPool2d(kernel_size=1, stride=1, padding=0, ceil_mode=False)\n",
        "        )\n",
        "\n",
        "        self.linear_layers = nn.Sequential(\n",
        "            # Define a fully connected layer with 3 input features and 3 output features\n",
        "            nn.Linear(3, 21)\n",
        "        )\n",
        "\n",
        "    # Define the forward pass\n",
        "    def forward(self, x):\n",
        "        x = self.cnn_layers(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.linear_layers(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Define the model, optimizer, and loss function\n",
        "model = CNNNet()  # Create an instance of the CNNNet class\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.0001)  # Define the optimizer with a learning rate of 0.0001\n",
        "criterion = nn.CrossEntropyLoss()  # Define the loss function as Cross-Entropy Loss\n",
        "\n",
        "# Check if GPU is available and move the model and loss function to the GPU if it is\n",
        "print(torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    model = model.to(\"cuda\")\n",
        "    criterion = criterion.to(\"cuda\")\n",
        "\n",
        "# Print the model architecture\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybc00-MQg2eb"
      },
      "outputs": [],
      "source": [
        "# CUDA launch functions synchronous - the program will wait for the GPU kernel to complete before proceeding.\n",
        "!export CUDA_LAUNCH_BLOCKING=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuwEZNxhSzWv",
        "outputId": "a719ecbf-ec6a-4f3f-e638-d990d890112f"
      },
      "outputs": [],
      "source": [
        "# Training the model for 30 epochs\n",
        "\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "for epoch in range(10):\n",
        "    running_loss = 0   # To accumulate training loss\n",
        "    correct_train = 0  # To track correct predictions during training\n",
        "    total_train = 0    # Total number of samples for training accuracy\n",
        "    \n",
        "    model.train()  # Set the model to training mode\n",
        "    for images, labels in trainloader:\n",
        "        if torch.cuda.is_available():\n",
        "            images = images.to(\"cuda\")\n",
        "            labels = labels.to(\"cuda\")\n",
        "\n",
        "        # Reset the gradients to zero\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(images)\n",
        "        labels = labels.type(torch.long)\n",
        "        \n",
        "        # Calculate the loss\n",
        "        loss = criterion(output, labels)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the model's weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update running loss\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        _, predicted = torch.max(output, 1)  # Get predicted class\n",
        "        correct_train += (predicted == labels).sum().item()  # Count correct predictions\n",
        "        total_train += labels.size(0)  # Total number of samples in the batch\n",
        "\n",
        "    # Calculate and print training accuracy\n",
        "    train_accuracy = correct_train / total_train * 100\n",
        "    avg_train_loss = running_loss / len(trainloader)\n",
        "\n",
        "    train_losses.append(avg_train_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    # Validation phase\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct_val = 0  # To track correct predictions during validation\n",
        "    total_val = 0    # Total number of samples for validation accuracy\n",
        "    val_loss = 0     # To accumulate validation loss\n",
        "    \n",
        "    with torch.no_grad():  # Disable gradient calculation for validation\n",
        "        for val_images, val_labels in testloader:\n",
        "            if torch.cuda.is_available():\n",
        "                val_images = val_images.to(\"cuda\")\n",
        "                val_labels = val_labels.to(\"cuda\")\n",
        "\n",
        "            # Forward pass on validation set\n",
        "            val_output = model(val_images)\n",
        "            val_labels = val_labels.type(torch.long)\n",
        "            # Calculate validation loss\n",
        "            v_loss = criterion(val_output, val_labels)\n",
        "            val_loss += v_loss.item()\n",
        "\n",
        "            # Calculate validation accuracy\n",
        "            _, val_predicted = torch.max(val_output, 1)\n",
        "            correct_val += (val_predicted == val_labels).sum().item()\n",
        "            total_val += val_labels.size(0)\n",
        "\n",
        "    # Calculate validation accuracy\n",
        "    val_accuracy = correct_val / total_val * 100\n",
        "    avg_val_loss = val_loss / len(testloader)  # Average validation loss per batch\n",
        "\n",
        "    val_losses.append(avg_val_loss)\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    # Print training and validation metrics for the epoch\n",
        "    print(f\"Epoch {epoch+1} - \"\n",
        "          f\"Training loss: {avg_train_loss:.4f}, \"\n",
        "          f\"Training accuracy: {train_accuracy:.4f}, \"\n",
        "          f\"Validation loss: {avg_val_loss:.4f}, \"\n",
        "          f\"Validation accuracy: {val_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot Loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label=\"Training Loss\")\n",
        "plt.plot(val_losses, label=\"Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training and Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_accuracies, label=\"Training Accuracy\")\n",
        "plt.plot(val_accuracies, label=\"Validation Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.title(\"Training and Validation Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ynUA5qki9JMZ"
      },
      "outputs": [],
      "source": [
        "# Define the file path where the model will be saved\n",
        "filepath = 'cnn.pt'\n",
        "\n",
        "# Save the model's state dictionary to the specified file path\n",
        "torch.save(model.state_dict(), filepath)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "NETMgFA_ZLIF"
      },
      "outputs": [],
      "source": [
        "# model_trained = CNNNet()\n",
        "# model_trained.load_state_dict(torch.load(filepath))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "oMV6tueigxm2"
      },
      "outputs": [],
      "source": [
        "# device = \"cuda\"--> use if you have GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQozc9rTgppA",
        "outputId": "78b36232-9f3b-4e9b-e842-659708c047bb"
      },
      "outputs": [],
      "source": [
        "# [.2, .5, .3]\n",
        "# y_pred_list = []\n",
        "# y_true_list = []\n",
        "# with torch.no_grad():\n",
        "#     for x_batch, y_batch in testloader:\n",
        "#         x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "#         y_test_pred = model(x_batch)\n",
        "#         print(y_test_pred)\n",
        "#         _, y_pred_tag = torch.max(y_test_pred, dim = 1)\n",
        "#         y_pred_list.extend(y_pred_tag.cpu().numpy())\n",
        "#         y_true_list.extend(y_batch.cpu().numpy())\n",
        "\n",
        "###\n",
        "\n",
        "# Prediction \n",
        "# Create empty lists to store predicted and true labels\n",
        "y_pred_list = []  # Predicted labels\n",
        "y_true_list = []  # True labels\n",
        "\n",
        "# Disable gradient calculations for inference\n",
        "with torch.no_grad():\n",
        "    for x_batch, y_batch in testloader:\n",
        "        x_batch, y_batch = x_batch.to(), y_batch.to()\n",
        "        \n",
        "        # Perform inference with the model\n",
        "        y_test_pred = model(x_batch)\n",
        "        print(y_test_pred)  # Display the model's predictions\n",
        "        \n",
        "        # Find the predicted class labels\n",
        "        _, y_pred_tag = torch.max(y_test_pred, dim=1)\n",
        "        \n",
        "        # Extend the lists with the predicted and true labels\n",
        "        y_pred_list.extend(y_pred_tag.cpu().numpy())\n",
        "        y_true_list.extend(y_batch.cpu().numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "nwcGG7jjhOuf"
      },
      "outputs": [],
      "source": [
        "# Extract the maximum values (class indices) from the true labels\n",
        "y_true_list_max = [m.argmax() for m in y_true_list]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUt3u8jag9v-",
        "outputId": "91de5bd3-9503-43bf-ced2-45dbb8f13cd2"
      },
      "outputs": [],
      "source": [
        "# Initialize variables to count correct and total predictions\n",
        "correct_count, all_count = 0, 0\n",
        "\n",
        "# Compare predicted labels (y_pred_list) with true labels (y_true_list_max)\n",
        "for i in range(len(y_pred_list)):\n",
        "    if y_pred_list[i] == y_true_list_max[i]:\n",
        "        correct_count += 1\n",
        "    all_count += 1\n",
        "\n",
        "# Calculate and print the model accuracy\n",
        "accuracy = correct_count / all_count\n",
        "print(\"\\nModel Accuracy =\", accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HKlMDs_9wgJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Step 1: Load and preprocess the image\n",
        "def preprocess_image(image_path):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((200, 200)),  # Resize to model input size\n",
        "        transforms.ToTensor(),         # Convert to tensor\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # Normalize\n",
        "    ])\n",
        "    image = Image.open(image_path).convert('RGB')  # Ensure it's an RGB image\n",
        "    image = transform(image)\n",
        "    return image.unsqueeze(0)  # Add batch dimension [1, C, H, W]\n",
        "\n",
        "# Step 2: Load your trained model\n",
        "model_trained = CNNNet()\n",
        "model_trained.load_state_dict(torch.load(\"model32.pt\", weights_only=True))\n",
        "model_trained.eval()\n",
        "# Step 3: Predict the class\n",
        "def predict(image_path, temp = 3.0):\n",
        "    image = preprocess_image(image_path)  # Preprocess the image\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        logits = model_trained(image)  # Pass the image through the model\n",
        "        print(logits)\n",
        "        probabilities = torch.softmax(logits, dim=1) \n",
        "        predicted_class = torch.argmax(logits, dim=1).item()  # Get the class index\n",
        "        confidence = probabilities[0, predicted_class].item()\n",
        "    return predicted_class, confidence\n",
        "\n",
        "# Example usage\n",
        "image_path = \"1.png\"  # Replace with your image path\n",
        "predicted_class, confidence = predict(image_path)\n",
        "print(f\"Predicted Class: {le.inverse_transform([predicted_class])}\")\n",
        "print(f\"Confidence Score: {confidence}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "CNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml_3_11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
